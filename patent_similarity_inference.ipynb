{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "'Darwin'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "environment = platform.system(); environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset_path = Path('us-patent-phrase-to-phrase-matching')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('patent_model/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['▁Greetings', ',', '▁fellow', '▁humans', '!']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Greetings, fellow humans!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def tokenize_document(document): return tokenizer(document['input'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Training Set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                 id     anchor                  target context  score\n0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>37d61fd2272659b1</td>\n      <td>abatement</td>\n      <td>abatement of pollution</td>\n      <td>A47</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7b9652b17b68b7a4</td>\n      <td>abatement</td>\n      <td>act of abating</td>\n      <td>A47</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36d72442aefd8232</td>\n      <td>abatement</td>\n      <td>active catalyst</td>\n      <td>A47</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5296b0c19e1ce60e</td>\n      <td>abatement</td>\n      <td>eliminating process</td>\n      <td>A47</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54c1e3b9184cb5b6</td>\n      <td>abatement</td>\n      <td>forest region</td>\n      <td>A47</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_csv(dataset_path/'train.csv'); training_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                      id                       anchor       target context\ncount              36473                        36473        36473   36473\nunique             36473                          733        29340     106\ntop     37d61fd2272659b1  component composite coating  composition     H01\nfreq                   1                          152           24    2186",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>36473</td>\n      <td>36473</td>\n      <td>36473</td>\n      <td>36473</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>36473</td>\n      <td>733</td>\n      <td>29340</td>\n      <td>106</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>37d61fd2272659b1</td>\n      <td>component composite coating</td>\n      <td>composition</td>\n      <td>H01</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>152</td>\n      <td>24</td>\n      <td>2186</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.describe(include='object')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process Training Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "training_df['input'] = training_df.agg(lambda document: f\"TEXT1: {document['context']}; TEXT2: {document['target']}; ANC1: {document['anchor']}\", axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "0    TEXT1: A47; TEXT2: abatement of pollution; ANC...\n1    TEXT1: A47; TEXT2: act of abating; ANC1: abate...\n2    TEXT1: A47; TEXT2: active catalyst; ANC1: abat...\n3    TEXT1: A47; TEXT2: eliminating process; ANC1: ...\n4    TEXT1: A47; TEXT2: forest region; ANC1: abatement\nName: input, dtype: object"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['input'].head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tokenize and Numericalize Training Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['id', 'anchor', 'target', 'context', 'score', 'input'],\n    num_rows: 36473\n})"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ds = Dataset.from_pandas(training_df); training_ds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3ef3b5938e44dcba31ea1ce7a019f77"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds = training_ds.map(tokenize_document, batched=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "('TEXT1: A47; TEXT2: abatement of pollution; ANC1: abatement',\n [1,\n  54453,\n  435,\n  294,\n  336,\n  5753,\n  346,\n  54453,\n  445,\n  294,\n  47284,\n  265,\n  6435,\n  346,\n  23702,\n  435,\n  294,\n  47284,\n  2])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_document = tokenized_ds[0]\n",
    "first_document['input'], first_document['input_ids']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "tokenized_ds = tokenized_ds.rename_columns({'score': 'labels'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Validation Set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 27354\n    })\n    test: Dataset({\n        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 9119\n    })\n})"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_dict = tokenized_ds.train_test_split(0.25, seed=42); ds_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                 id              anchor                         target context\n0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02\n1  09e418c93a776564     adjust gas flow              altering gas flow     F23\n2  36baf228038e314b      lower trunnion                 lower locating     B60\n3  1f37ead645e7f0c8       cap component                  upper portion     D06\n4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4112d61851461f60</td>\n      <td>opc drum</td>\n      <td>inorganic photoconductor drum</td>\n      <td>G02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>09e418c93a776564</td>\n      <td>adjust gas flow</td>\n      <td>altering gas flow</td>\n      <td>F23</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36baf228038e314b</td>\n      <td>lower trunnion</td>\n      <td>lower locating</td>\n      <td>B60</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1f37ead645e7f0c8</td>\n      <td>cap component</td>\n      <td>upper portion</td>\n      <td>D06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>71a5b6ad068d531f</td>\n      <td>neural stimulation</td>\n      <td>artificial neural network</td>\n      <td>H04</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df = pd.read_csv(dataset_path/'test.csv'); testing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                      id      anchor                         target context\ncount                 36          36                             36      36\nunique                36          34                             36      29\ntop     4112d61851461f60  el display  inorganic photoconductor drum     G02\nfreq                   1           2                              1       3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>36</td>\n      <td>34</td>\n      <td>36</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>4112d61851461f60</td>\n      <td>el display</td>\n      <td>inorganic photoconductor drum</td>\n      <td>G02</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df['input'] = testing_df.agg(lambda document: f\"TEXT1: {document['context']}; TEXT2: {document['target']}; ANC1: {document['anchor']}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0ae70a74a624d3eb435c7ccde7a9f01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['id', 'anchor', 'target', 'context', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 36\n})"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_ds = Dataset.from_pandas(testing_df).map(tokenize_document, batched=True)\n",
    "testing_ds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Metric Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "def pear_corr_dict(prediction):\n",
    "    return {'pearson': np.corrcoef(*prediction)[0][1]}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoConfig, \\\n",
    "    Trainer, TrainingArguments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "batch_size, epochs, learning_rate = 32, 4, 8e-5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "if environment == 'Darwin':\n",
    "    # Use MPS device instead of fp16.\n",
    "    arguments = TrainingArguments(\n",
    "        'outputs',\n",
    "        learning_rate = learning_rate,\n",
    "        warmup_ratio = 0.1,\n",
    "        lr_scheduler_type = 'cosine',\n",
    "        # Setting the below parameter to False because it's not working.\n",
    "        use_mps_device=False,\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        per_device_train_batch_size = batch_size,\n",
    "        per_device_eval_batch_size = batch_size*2,\n",
    "        num_train_epochs = epochs,\n",
    "        weight_decay = 0.01,\n",
    "        report_to='none'\n",
    "    )\n",
    "else:\n",
    "    # Use fp16 instead of MPS device.\n",
    "    arguments = TrainingArguments(\n",
    "        'outputs',\n",
    "        learning_rate = learning_rate,\n",
    "        warmup_ratio = 0.1,\n",
    "        lr_scheduler_type = 'cosine',\n",
    "        fp16 = True,\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        per_device_train_batch_size = batch_size,\n",
    "        per_device_eval_batch_size = batch_size*2,\n",
    "        num_train_epochs = epochs,\n",
    "        weight_decay = 0.01,\n",
    "        report_to='none'\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('patent_model/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('patent_model/',\n",
    "                                                           config=config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    arguments,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=pear_corr_dict,\n",
    "    train_dataset=ds_dict['train'],\n",
    "    eval_dataset=ds_dict['test'],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finally! Inference."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: id, input, target, anchor, context. If id, input, target, anchor, context are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/Users/salmannaqvi/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n",
      "/Users/salmannaqvi/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n",
      "/Users/salmannaqvi/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(testing_ds).predictions.astype(float)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.35],\n       [ 0.76],\n       [ 0.56],\n       [ 0.31],\n       [-0.02],\n       [ 0.56],\n       [ 0.53],\n       [-0.02],\n       [ 0.32],\n       [ 1.07],\n       [ 0.25],\n       [ 0.27],\n       [ 0.85],\n       [ 0.95],\n       [ 0.75],\n       [ 0.47],\n       [ 0.3 ],\n       [-0.  ],\n       [ 0.62],\n       [ 0.39],\n       [ 0.49],\n       [ 0.28],\n       [ 0.17],\n       [ 0.27],\n       [ 0.55],\n       [-0.01],\n       [-0.02],\n       [-0.03],\n       [-0.02],\n       [ 0.56],\n       [ 0.3 ],\n       [-0.01],\n       [ 0.73],\n       [ 0.54],\n       [ 0.49],\n       [ 0.25]])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some are larger than 1 and less than 0. Let's apply a ReLU to fix it, though\n",
    "there are better ways to do fix it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.35],\n       [0.76],\n       [0.56],\n       [0.31],\n       [0.  ],\n       [0.56],\n       [0.53],\n       [0.  ],\n       [0.32],\n       [1.  ],\n       [0.25],\n       [0.27],\n       [0.85],\n       [0.95],\n       [0.75],\n       [0.47],\n       [0.3 ],\n       [0.  ],\n       [0.62],\n       [0.39],\n       [0.49],\n       [0.28],\n       [0.17],\n       [0.27],\n       [0.55],\n       [0.  ],\n       [0.  ],\n       [0.  ],\n       [0.  ],\n       [0.56],\n       [0.3 ],\n       [0.  ],\n       [0.73],\n       [0.54],\n       [0.49],\n       [0.25]])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.clip(predictions, 0, 1); predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create submission file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "713873f692474ed88d93c1af344aec24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "853"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = datasets.Dataset.from_dict({\n",
    "    'id': testing_ds['id'],\n",
    "    'score': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2325d4fde750cacac60ba4c06f149a07b5aad47b4e6bf1c4dca1c7b2184bba3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
